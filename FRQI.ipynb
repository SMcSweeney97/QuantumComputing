{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 23:23:44.043109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training examples: 60000\n",
      "Original Test examples: 10000\n",
      "Number of filtered training examples: 12049\n",
      "Number of filtered test examples: 1968\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "Model: \"QNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 10)]              0         \n",
      "                                                                 \n",
      " quantumLayer (KerasLayer)   (None, 1)                 57        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 23:25:08.118900: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/60\n",
      "377/377 [==============================] - 1631s 4s/step - loss: 0.9942 - accuracy: 0.5086 - val_loss: 0.9855 - val_accuracy: 0.5126\n",
      "Epoch 2/60\n",
      "377/377 [==============================] - 1622s 4s/step - loss: 0.9888 - accuracy: 0.5088 - val_loss: 0.9794 - val_accuracy: 0.5126\n",
      "Epoch 3/60\n",
      "377/377 [==============================] - 1621s 4s/step - loss: 0.9857 - accuracy: 0.5086 - val_loss: 0.9769 - val_accuracy: 0.5126\n",
      "Epoch 4/60\n",
      "377/377 [==============================] - 1620s 4s/step - loss: 0.9844 - accuracy: 0.5086 - val_loss: 0.9758 - val_accuracy: 0.5126\n",
      "Epoch 5/60\n",
      "377/377 [==============================] - 1622s 4s/step - loss: 0.9838 - accuracy: 0.5087 - val_loss: 0.9752 - val_accuracy: 0.5126\n",
      "Epoch 6/60\n",
      "377/377 [==============================] - 1621s 4s/step - loss: 0.9834 - accuracy: 0.5086 - val_loss: 0.9747 - val_accuracy: 0.5126\n",
      "Epoch 7/60\n",
      "377/377 [==============================] - 1622s 4s/step - loss: 0.9831 - accuracy: 0.5091 - val_loss: 0.9743 - val_accuracy: 0.5126\n",
      "Epoch 8/60\n",
      "377/377 [==============================] - 1617s 4s/step - loss: 0.9829 - accuracy: 0.5089 - val_loss: 0.9742 - val_accuracy: 0.5126\n",
      "Epoch 9/60\n",
      "377/377 [==============================] - 1618s 4s/step - loss: 0.9828 - accuracy: 0.5089 - val_loss: 0.9739 - val_accuracy: 0.5126\n",
      "Epoch 10/60\n",
      "377/377 [==============================] - 1621s 4s/step - loss: 0.9826 - accuracy: 0.5086 - val_loss: 0.9738 - val_accuracy: 0.5126\n",
      "Epoch 11/60\n",
      "377/377 [==============================] - 1622s 4s/step - loss: 0.9826 - accuracy: 0.5088 - val_loss: 0.9738 - val_accuracy: 0.5126\n",
      "Epoch 12/60\n",
      "377/377 [==============================] - 1625s 4s/step - loss: 0.9825 - accuracy: 0.5086 - val_loss: 0.9737 - val_accuracy: 0.5126\n",
      "Epoch 13/60\n",
      "377/377 [==============================] - 1620s 4s/step - loss: 0.9825 - accuracy: 0.5087 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 14/60\n",
      "377/377 [==============================] - 1633s 4s/step - loss: 0.9825 - accuracy: 0.5085 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 15/60\n",
      "377/377 [==============================] - 1667s 4s/step - loss: 0.9825 - accuracy: 0.5092 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 16/60\n",
      "377/377 [==============================] - 1621s 4s/step - loss: 0.9824 - accuracy: 0.5089 - val_loss: 0.9737 - val_accuracy: 0.5126\n",
      "Epoch 17/60\n",
      "377/377 [==============================] - 1621s 4s/step - loss: 0.9827 - accuracy: 0.5090 - val_loss: 0.9738 - val_accuracy: 0.5126\n",
      "Epoch 18/60\n",
      "377/377 [==============================] - 1621s 4s/step - loss: 0.9825 - accuracy: 0.5089 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 19/60\n",
      "377/377 [==============================] - 1619s 4s/step - loss: 0.9824 - accuracy: 0.5090 - val_loss: 0.9748 - val_accuracy: 0.5126\n",
      "Epoch 20/60\n",
      "377/377 [==============================] - 1621s 4s/step - loss: 0.9825 - accuracy: 0.5088 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 21/60\n",
      "377/377 [==============================] - 1622s 4s/step - loss: 0.9824 - accuracy: 0.5089 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 22/60\n",
      "377/377 [==============================] - 1687s 4s/step - loss: 0.9824 - accuracy: 0.5091 - val_loss: 0.9737 - val_accuracy: 0.5126\n",
      "Epoch 23/60\n",
      "377/377 [==============================] - 1744s 5s/step - loss: 0.9825 - accuracy: 0.5088 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 24/60\n",
      "377/377 [==============================] - 1703s 5s/step - loss: 0.9825 - accuracy: 0.5090 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 25/60\n",
      "377/377 [==============================] - 1680s 4s/step - loss: 0.9825 - accuracy: 0.5089 - val_loss: 0.9737 - val_accuracy: 0.5126\n",
      "Epoch 26/60\n",
      "377/377 [==============================] - 1668s 4s/step - loss: 0.9825 - accuracy: 0.5088 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 27/60\n",
      "377/377 [==============================] - 1641s 4s/step - loss: 0.9825 - accuracy: 0.5089 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 28/60\n",
      "377/377 [==============================] - 1737s 5s/step - loss: 0.9825 - accuracy: 0.5088 - val_loss: 0.9736 - val_accuracy: 0.5126\n",
      "Epoch 29/60\n",
      "246/377 [==================>...........] - ETA: 9:19 - loss: 0.9844 - accuracy: 0.5079"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import pennylane.templates.embeddings as qml_embeddings\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "\n",
    "class Preprocessing():\n",
    "\n",
    "    def __init__(self, dataset, samples_per_class=100):\n",
    "        (x_train, y_train), (x_test, y_test) = dataset\n",
    "\n",
    "        x_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0\n",
    "\n",
    "        print('Original Training examples: {}'.format(len(x_train)))\n",
    "        print('Original Test examples: {}'.format(len(x_test)))\n",
    "\n",
    "        self.x_train, self.y_train = self.filter_classes(x_train, y_train)\n",
    "        self.x_test, self.y_test = self.filter_classes(x_test, y_test)\n",
    "        \n",
    "        # Limit the number of samples per class\n",
    "        #self.x_train, self.y_train = self.limit_samples(self.x_train, self.y_train, samples_per_class)\n",
    "        #self.x_test, self.y_test = self.limit_samples(self.x_test, self.y_test, samples_per_class)\n",
    "        \n",
    "        self.x_train = self.x_train.reshape(self.x_train.shape[0], -1)\n",
    "        self.x_test = self.x_test.reshape(self.x_test.shape[0], -1)\n",
    "        \n",
    "        gamma = 1.0  # Adjust the gamma parameter as needed\n",
    "        self.kernel_matrix_train = self.rbf_kernel_matrix(self.x_train, self.x_train, gamma)\n",
    "        self.kernel_matrix_test = self.rbf_kernel_matrix(self.x_test, self.x_train, gamma)\n",
    "        \n",
    "        self.kernel_matrix_train = self.reduce_dimensions(self.kernel_matrix_train, 10)\n",
    "        self.kernel_matrix_test = self.reduce_dimensions(self.kernel_matrix_test, 10)\n",
    "\n",
    "\n",
    "        print('Number of filtered training examples: {}'.format(len(self.x_train)))\n",
    "        print('Number of filtered test examples: {}'.format(len(self.x_test)))\n",
    "\n",
    "        self.plot(self.x_train[0, :, :, 0], '28x28 Training Example')\n",
    "  \n",
    "    def filter_classes(self, x, y):\n",
    "        keep = (y == 3) | (y == 6)\n",
    "        x, y = x[keep], y[keep]\n",
    "        y = y == 3\n",
    "        return x, y\n",
    "    \n",
    "    def plot(self, image, title, vmin = None, vmax = None):\n",
    "        plt.imshow(image, cmap = 'Greys')\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.title(title, fontsize = 20)\n",
    "        plt.show()\n",
    "\n",
    "    def shrink(self, matrix):\n",
    "        new_data = tf.image.resize(matrix, (9, 9)).numpy()\n",
    "        \n",
    "        return new_data\n",
    "    \n",
    "    def limit_samples(self, x_data, y_data, samples_per_class):\n",
    "        unique_classes = np.unique(y_data)\n",
    "        x_data_limited = np.empty((0, x_data.shape[1] * x_data.shape[2]))\n",
    "        y_data_limited = np.empty(0, dtype=y_data.dtype)\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            indices = np.where(y_data == cls)\n",
    "            x_cls = x_data[indices][:samples_per_class]\n",
    "            y_cls = y_data[indices][:samples_per_class]\n",
    "            \n",
    "            x_cls = x_cls.reshape(x_cls.shape[0], -1)\n",
    "\n",
    "            x_data_limited = np.vstack((x_data_limited, x_cls))\n",
    "            y_data_limited = np.hstack((y_data_limited, y_cls))\n",
    "\n",
    "        return x_data_limited, y_data_limited\n",
    "    \n",
    "    def reduce_dimensions(self, kernel_matrix, n_dimensions):\n",
    "        pca = PCA(n_components=n_dimensions)\n",
    "        reduced_kernel_matrix = pca.fit_transform(kernel_matrix)\n",
    "\n",
    "        return reduced_kernel_matrix\n",
    "\n",
    "    def rbf_kernel_matrix(x1, x2, gamma):\n",
    "        pairwise_dists = cdist(x1, x2, 'euclidean')\n",
    "        K = np.exp(-gamma * pairwise_dists ** 2)\n",
    "        return K\n",
    "\n",
    "\n",
    "class QuantumNeuralNetwork():\n",
    "    def __init__(self, kernel_matrix_train, y_train, kernel_matrix_test, y_test, epochs):\n",
    "        self.epochs = epochs\n",
    "        model_1l = self.generate_model(kernel_matrix_train, kernel_matrix_test, layers = 1)\n",
    "        model_1l.compile(\n",
    "            loss = tf.keras.losses.Hinge(),\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            metrics = [self.accuracy])\n",
    "        history_1l, results_1l, model_1l = self.train_model(model_1l, kernel_matrix_train, y_train, kernel_matrix_test, y_test)\n",
    "        model_1l.save('model_1l.h5')\n",
    "        history_1l_df = pd.DataFrame(history_1l.history)\n",
    "        with open('history_1l.csv', mode = 'w') as f:\n",
    "            history_1l_df.to_csv(f)\n",
    "        print('\\nModel 1 complete!\\n')\n",
    "\n",
    "    def generate_model(self, kernel_matrix_train, kernel_matrix_test, layers):\n",
    "        n_qubits = 10\n",
    "        n_layers = layers\n",
    "        dev = qml.device('default.qubit', wires = n_qubits)\n",
    "\n",
    "        @qml.qnode(dev, diff_method = 'adjoint')\n",
    "        def qnode(inputs, weights):\n",
    "            qml_embeddings.AngleEmbedding(inputs, wires=range(n_qubits), rotation='Y')\n",
    "\n",
    "            for ii in range(n_qubits):\n",
    "                qml.RY(np.pi * inputs[ii], wires = ii)\n",
    "\n",
    "\n",
    "            for jj in range(n_layers):\n",
    "                for ii in range(n_qubits - 1):\n",
    "                    qml.RZ(weights[jj, 2 * ii, 0], wires = 0)\n",
    "                    qml.RY(weights[jj, 2 * ii, 1], wires = 0)\n",
    "                    qml.RZ(weights[jj, 2 * ii, 2], wires = 0)\n",
    "\n",
    "                    qml.RZ(weights[jj, 2 * ii + 1, 0], wires = ii + 1)\n",
    "                    qml.RY(weights[jj, 2 * ii + 1, 1], wires = ii + 1)\n",
    "                    qml.RZ(weights[jj, 2 * ii + 1, 2], wires = ii + 1)\n",
    "\n",
    "                    qml.CNOT(wires = [ii + 1, 0])\n",
    "                    \n",
    "                qml.RZ(weights[jj, 2 * (n_qubits - 1), 0], wires = 0)\n",
    "                qml.RY(weights[jj, 2 * (n_qubits - 1), 1], wires = 0)\n",
    "                qml.RZ(weights[jj, 2 * (n_qubits - 1), 2], wires = 0)\n",
    "\n",
    "            return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "        weight_shapes = {'weights': (n_layers, 2 * (n_qubits - 1) + 1, 3)}\n",
    "        qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim = 1, name = 'quantumLayer')\n",
    "        inputs = tf.keras.Input(shape=(n_qubits,), name='inputs')\n",
    "        outputs = qlayer(inputs)\n",
    "        model = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'QNN')\n",
    "        x = np.reshape(kernel_matrix_test[0,:], (1, -1))\n",
    "        model.predict(x)\n",
    "        print(model.summary())\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def train_model(self, model, kernel_matrix_train, y_train, kernel_matrix_test, y_test):\n",
    "        EPOCHS = self.epochs\n",
    "        BATCH_SIZE = 32\n",
    "        NUM_EXAMPLES = kernel_matrix_train.shape[0]\n",
    "\n",
    "        x_train_sub = kernel_matrix_train[:NUM_EXAMPLES, :]\n",
    "\n",
    "        y_train_hinge = 2.0 * y_train - 1.0\n",
    "        y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]\n",
    "\n",
    "        x_test_sub = kernel_matrix_test[:, :]\n",
    "        y_test_sub = y_test[:]\n",
    "\n",
    "        qnn_history = model.fit(\n",
    "            x_train_sub,\n",
    "            y_train_hinge_sub,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            epochs = EPOCHS,\n",
    "            verbose = 1,\n",
    "            validation_data = (x_test_sub, y_test_sub))\n",
    "        \n",
    "        qnn_results = model.evaluate(x_test_sub, y_test_sub)\n",
    "        \n",
    "        return qnn_history, qnn_results, model\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        y_true = tf.squeeze(y_true) > 0.0\n",
    "        y_pred = tf.squeeze(y_pred) > 0.0\n",
    "        result = tf.cast(y_true == y_pred, tf.float32)\n",
    "\n",
    "        return tf.reduce_mean(result)\n",
    "\n",
    "class Plot():\n",
    "    def __init__(self,\n",
    "                 history_1l,\n",
    "                 epochs):\n",
    "        for col in history_1l.columns:\n",
    "            plt.plot(np.arange(1, epochs + 1), history_1l[col], label = '1 layer QNN')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel(col)\n",
    "            plt.legend()\n",
    "            plt.xticks(np.arange(0, epochs + 1, 2))\n",
    "            plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "            plt.savefig('{}.png'.format(col), bbox_inches = 'tight', pad_inches = 0)\n",
    "            plt.show()\n",
    "    \n",
    "def main():\n",
    "    epochs = 60\n",
    "    dataset = Preprocessing(tf.keras.datasets.mnist.load_data(), samples_per_class=10000)\n",
    "    kernel_matrix_train, y_train, kernel_matrix_test, y_test = dataset.kernel_matrix_train, dataset.y_train, dataset.kernel_matrix_test, dataset.y_test\n",
    "    QuantumNeuralNetwork(kernel_matrix_train, y_train, kernel_matrix_test, y_test, epochs)\n",
    "\n",
    "    history_1l = pd.read_csv('history_1l.csv')\n",
    "    Plot(history_1l,\n",
    "         epochs)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zombies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
